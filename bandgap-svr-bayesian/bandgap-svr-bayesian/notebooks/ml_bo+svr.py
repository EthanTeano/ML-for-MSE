# -*- coding: utf-8 -*-
"""ML BO+SVR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_PCCh9I6P5Q0gzxruupLPasogw8wUiW
"""

# Install dependencies
!pip install scikit-learn pandas numpy openpyxl joblib optuna[visualization]

# 1) Imports
import pandas as pd
import numpy as np
import optuna
from google.colab import files
import io
from sklearn.svm import SVR
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error
import joblib
import optuna.visualization as vis

# 2) Upload & Load Data
uploaded = files.upload()  # select your Excel file
filename = next(iter(uploaded))
df = pd.read_excel(io.BytesIO(uploaded[filename]))

# 3) Drop rows with missing values
df = df.dropna()

# 4) Prepare Features & Target
X = df.drop(columns=["material_id", "band_gap (eV)"])
y = df["band_gap (eV)"]

# 5) Train/Test Split (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 6) Define Optuna Objective (CV on train only)
def objective(trial):
    C       = trial.suggest_loguniform('C',       1e-3,   1e3)
    epsilon = trial.suggest_loguniform('epsilon', 1e-5,   2.0)
    gamma   = trial.suggest_loguniform('gamma',   1e-5,   100.0)

    model = make_pipeline(
        StandardScaler(),
        SVR(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)
    )

    scores = cross_val_score(
        model, X_train, y_train,
        cv=5, scoring='neg_mean_squared_error'
    )
    rmse = (-scores.mean())**0.5
    return rmse

# 7) Run Optimization
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=100)

print("â–¶ Best CV RMSE:", study.best_value)
print("â–¶ Best hyperparameters:", study.best_params)

# 8) Retrain Final Model on Full Training Set
best_model = make_pipeline(
    StandardScaler(),
    SVR(kernel='rbf', **study.best_params)
)
best_model.fit(X_train, y_train)

# 8) Evaluate on the Hold-out Test Set
y_pred = best_model.predict(X_test)

# Compute RMSE without the `squared` argument
from sklearn.metrics import mean_squared_error
import numpy as np

mse = mean_squared_error(y_test, y_pred)
test_rmse = np.sqrt(mse)
print("â–¶ Hold-out Test RMSE:", test_rmse)

# 10) (Optional) Visualize Optimization & Importances
fig1 = vis.plot_optimization_history(study)
fig2 = vis.plot_param_importances(study)
fig1.show()
fig2.show()

# 11) (Optional) Save the Final Model
joblib.dump(best_model, "best_svr_model.pkl")
files.download("best_svr_model.pkl")

# STEP 1: Install dependencies
!pip install scikit-learn matplotlib pandas joblib openpyxl

# STEP 2: Upload & load the trained model
from google.colab import files
import joblib

print("ðŸ”¹ Upload your .pkl model file:")
uploaded_model = files.upload()
model_filename = next(f for f in uploaded_model if f.endswith('.pkl'))
model = joblib.load(model_filename)

# STEP 3: Upload & load the Excel data
import io
import pandas as pd

print("\nðŸ”¹ Now upload your .xlsx data file:")
uploaded_data = files.upload()
data_filename = next(f for f in uploaded_data if f.endswith('.xlsx'))
df = pd.read_excel(io.BytesIO(uploaded_data[data_filename]))

# STEP 4: Clean data and split
df = df.dropna()  # drop any NaNs
X = df.drop(columns=["material_id", "band_gap (eV)"])
y = df["band_gap (eV)"]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# STEP 5: Predict on the test set and plot
import matplotlib.pyplot as plt

y_pred = model.predict(X_test)

plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
         linestyle='--', color='gray')
plt.xlabel("True Band Gap (eV)")
plt.ylabel("Predicted Band Gap (eV)")
plt.title("SVR Model: True vs. Predicted Band Gaps")
plt.grid(True)
plt.show()

# â”€â”€â”€ STEP 0: Install dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
!pip install scikit-learn pandas numpy matplotlib joblib openpyxl

# â”€â”€â”€ STEP 1: Upload and load your trained model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from google.colab import files
import joblib

print("ðŸ”¹ Upload your trained model (.pkl):")
uploaded = files.upload()
model_path = next(f for f in uploaded if f.endswith('.pkl'))
model = joblib.load(model_path)

# â”€â”€â”€ STEP 2: Upload and load your data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import io
import pandas as pd

print("\nðŸ”¹ Upload your dataset (.xlsx):")
uploaded = files.upload()
data_path = next(f for f in uploaded if f.endswith('.xlsx'))
df = pd.read_excel(io.BytesIO(uploaded[data_path]))

# â”€â”€â”€ STEP 3: Clean & split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Drop any rows with missing values
df = df.dropna()

# Separate features and target
X = df.drop(columns=["material_id", "band_gap (eV)"])
y = df["band_gap (eV)"]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# â”€â”€â”€ STEP 4: Compute Permutation Importances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from sklearn.inspection import permutation_importance
import numpy as np

# Evaluate on the hold-out test set
results = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)
importances = results.importances_mean
stds        = results.importances_std
features    = X.columns

# Build a DataFrame of results
importance_df = pd.DataFrame({
    "feature":          features,
    "importance_mean":  importances,
    "importance_std":   stds
}).sort_values("importance_mean", ascending=False)

# Print the top 10 features by importance
print("\nâŸ³ Top 10 Features by Permutation Importance:")
print(importance_df.head(10).to_string(index=False))

# â”€â”€â”€ STEP 5: Plot the Importances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.barh(importance_df["feature"], importance_df["importance_mean"])
plt.errorbar(importance_df["importance_mean"], importance_df["feature"],
             xerr=importance_df["importance_std"], fmt="o", linewidth=1)
plt.xlabel("Mean Increase in Test RMSE")
plt.title("Permutation Feature Importances")
plt.gca().invert_yaxis()  # Highest importance at top
plt.tight_layout()
plt.show()